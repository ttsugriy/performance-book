{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-0",
   "source": [
    "# Investigation: Matrix Multiply\n",
    "\n",
    "**From The Nature of Fast, Chapter 10**\n",
    "\n",
    "Two matrix multiply implementations. Same algorithm. Same hardware. Same inputs.\n",
    "One is 200√ó faster. This notebook shows you why.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ttsugriy/performance-book/blob/main/notebooks/tier2-experimental/10-matrix-multiply.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-1",
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-2",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try to import numba for JIT compilation\n",
    "try:\n",
    "    from numba import jit, prange\n",
    "    HAS_NUMBA = True\n",
    "    print(\"‚úì Numba available for JIT compilation\")\n",
    "except ImportError:\n",
    "    HAS_NUMBA = False\n",
    "    print(\"‚ö†Ô∏è Numba not available. Install with: pip install numba\")\n",
    "    print(\"   (Some benchmarks will be slow)\")\n",
    "\n",
    "print(f\"\\nPython: {platform.python_version()}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Platform: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-3",
   "source": [
    "## The Problem\n",
    "\n",
    "Multiply two 1024√ó1024 matrices. Simple, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-4",
   "outputs": [],
   "source": [
    "# Setup: Create test matrices\n",
    "N = 512  # Using 512 to keep demo fast; the book uses 2048\n",
    "A = np.random.randn(N, N).astype(np.float32)\n",
    "B = np.random.randn(N, N).astype(np.float32)\n",
    "C = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "print(f\"Matrix size: {N}√ó{N}\")\n",
    "print(f\"Memory per matrix: {N * N * 4 / 1e6:.1f} MB\")\n",
    "print(f\"Total FLOPs: {2 * N**3 / 1e9:.2f} billion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-5",
   "source": [
    "## Implementation 1: Triple Nested Loop (Naive)\n",
    "\n",
    "The textbook algorithm: C[i,j] = Œ£_k A[i,k] √ó B[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-6",
   "outputs": [],
   "source": [
    "def matmul_naive_python(A, B, C):\n",
    "    \"\"\"Pure Python triple loop - will be very slow!\"\"\"\n",
    "    M, K = A.shape\n",
    "    K, N = B.shape\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            total = 0.0\n",
    "            for k in range(K):\n",
    "                total += A[i, k] * B[k, j]\n",
    "            C[i, j] = total\n",
    "    return C\n",
    "\n",
    "if HAS_NUMBA:\n",
    "    @jit(nopython=True)\n",
    "    def matmul_naive(A, B, C):\n",
    "        \"\"\"Naive i-j-k loop order.\"\"\"\n",
    "        M, K = A.shape\n",
    "        K, N = B.shape\n",
    "        for i in range(M):\n",
    "            for j in range(N):\n",
    "                total = 0.0\n",
    "                for k in range(K):\n",
    "                    total += A[i, k] * B[k, j]\n",
    "                C[i, j] = total\n",
    "        return C\n",
    "else:\n",
    "    matmul_naive = matmul_naive_python\n",
    "\n",
    "# Warmup and test\n",
    "C_naive = np.zeros((N, N), dtype=np.float32)\n",
    "if N <= 256 or HAS_NUMBA:  # Only run if fast enough\n",
    "    _ = matmul_naive(A[:64, :64], B[:64, :64], np.zeros((64, 64), dtype=np.float32))\n",
    "    print(\"Naive implementation ready\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping naive warmup (too slow without Numba)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-7",
   "source": [
    "## Implementation 2: Reordered Loops (i-k-j)\n",
    "\n",
    "**Key insight**: The order of loops matters for memory access!\n",
    "\n",
    "- Naive (i-j-k): Accesses B column-wise (strided access)\n",
    "- Reordered (i-k-j): Accesses B row-wise (sequential access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-8",
   "outputs": [],
   "source": [
    "if HAS_NUMBA:\n",
    "    @jit(nopython=True)\n",
    "    def matmul_reordered(A, B, C):\n",
    "        \"\"\"Reordered i-k-j loop - better memory access!\"\"\"\n",
    "        M, K = A.shape\n",
    "        K, N = B.shape\n",
    "        C[:] = 0  # Reset\n",
    "        for i in range(M):\n",
    "            for k in range(K):\n",
    "                a_val = A[i, k]  # Load once\n",
    "                for j in range(N):\n",
    "                    C[i, j] += a_val * B[k, j]  # Sequential access!\n",
    "        return C\n",
    "    \n",
    "    # Warmup\n",
    "    _ = matmul_reordered(A[:64, :64], B[:64, :64], np.zeros((64, 64), dtype=np.float32))\n",
    "    print(\"Reordered implementation ready\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Reordered version requires Numba\")\n",
    "    matmul_reordered = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-9",
   "source": [
    "## Implementation 3: Tiled (Cache-Friendly)\n",
    "\n",
    "Process in blocks that fit in cache!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-10",
   "outputs": [],
   "source": [
    "if HAS_NUMBA:\n",
    "    @jit(nopython=True)\n",
    "    def matmul_tiled(A, B, C, tile_size=32):\n",
    "        \"\"\"Tiled matrix multiply for cache efficiency.\"\"\"\n",
    "        M, K = A.shape\n",
    "        K, N = B.shape\n",
    "        C[:] = 0\n",
    "        \n",
    "        for i0 in range(0, M, tile_size):\n",
    "            for j0 in range(0, N, tile_size):\n",
    "                for k0 in range(0, K, tile_size):\n",
    "                    # Process one tile\n",
    "                    i_end = min(i0 + tile_size, M)\n",
    "                    j_end = min(j0 + tile_size, N)\n",
    "                    k_end = min(k0 + tile_size, K)\n",
    "                    \n",
    "                    for i in range(i0, i_end):\n",
    "                        for k in range(k0, k_end):\n",
    "                            a_val = A[i, k]\n",
    "                            for j in range(j0, j_end):\n",
    "                                C[i, j] += a_val * B[k, j]\n",
    "        return C\n",
    "    \n",
    "    # Warmup\n",
    "    _ = matmul_tiled(A[:64, :64], B[:64, :64], np.zeros((64, 64), dtype=np.float32))\n",
    "    print(\"Tiled implementation ready\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Tiled version requires Numba\")\n",
    "    matmul_tiled = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-11",
   "source": [
    "## Implementation 4: NumPy (BLAS)\n",
    "\n",
    "NumPy uses highly optimized BLAS libraries (OpenBLAS, MKL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-12",
   "outputs": [],
   "source": [
    "def matmul_numpy(A, B, C):\n",
    "    \"\"\"Use NumPy's optimized matrix multiply.\"\"\"\n",
    "    np.matmul(A, B, out=C)\n",
    "    return C\n",
    "\n",
    "# Warmup\n",
    "_ = matmul_numpy(A, B, C.copy())\n",
    "print(\"NumPy/BLAS implementation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-13",
   "source": [
    "## Benchmark: The Moment of Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-14",
   "outputs": [],
   "source": [
    "def benchmark(fn, A, B, C, num_runs=3, name=\"\"):\n",
    "    \"\"\"Benchmark a matrix multiply function.\"\"\"\n",
    "    times = []\n",
    "    for _ in range(num_runs):\n",
    "        C_test = C.copy()\n",
    "        start = time.perf_counter()\n",
    "        fn(A, B, C_test)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        times.append(elapsed)\n",
    "    \n",
    "    mean_time = np.mean(times)\n",
    "    flops = 2 * A.shape[0] * A.shape[1] * B.shape[1]\n",
    "    gflops = flops / mean_time / 1e9\n",
    "    \n",
    "    print(f\"{name:20s}: {mean_time:8.4f}s ({gflops:6.2f} GFLOPS)\")\n",
    "    return mean_time, gflops\n",
    "\n",
    "print(f\"Benchmarking {N}√ó{N} matrix multiply...\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# NumPy first (always available)\n",
    "t, gf = benchmark(matmul_numpy, A, B, C.copy(), name=\"NumPy (BLAS)\")\n",
    "results['NumPy'] = (t, gf)\n",
    "\n",
    "if HAS_NUMBA:\n",
    "    # Run our implementations\n",
    "    t, gf = benchmark(matmul_tiled, A, B, C.copy(), name=\"Tiled (32√ó32)\")\n",
    "    results['Tiled'] = (t, gf)\n",
    "    \n",
    "    t, gf = benchmark(matmul_reordered, A, B, C.copy(), name=\"Reordered (i-k-j)\")\n",
    "    results['Reordered'] = (t, gf)\n",
    "    \n",
    "    if N <= 256:  # Only run naive for small matrices\n",
    "        t, gf = benchmark(matmul_naive, A, B, C.copy(), name=\"Naive (i-j-k)\")\n",
    "        results['Naive'] = (t, gf)\n",
    "    else:\n",
    "        print(f\"{'Naive (i-j-k)':20s}: (skipped - too slow for N={N})\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-15",
   "source": [
    "## Analysis: Why Is There Such a Difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-16",
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "if len(results) > 1:\n",
    "    names = list(results.keys())\n",
    "    gflops = [results[n][1] for n in names]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(names, gflops, color=['green', 'blue', 'orange', 'red'][:len(names)])\n",
    "    plt.ylabel('GFLOPS', fontsize=12)\n",
    "    plt.title(f'Matrix Multiply Performance ({N}√ó{N})', fontsize=14)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, gf in zip(bars, gflops):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                 f'{gf:.1f}', ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate speedups\n",
    "    baseline = results.get('Naive', results.get('Reordered', (1, 1)))[1]\n",
    "    print(\"\\nSpeedups relative to slowest:\")\n",
    "    for name, (t, gf) in sorted(results.items(), key=lambda x: x[1][1]):\n",
    "        print(f\"  {name}: {gf/baseline:.1f}√ó\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-17",
   "source": [
    "## Investigation: Why Does Loop Order Matter?\n",
    "\n",
    "Let's visualize the memory access patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-18",
   "outputs": [],
   "source": [
    "def visualize_access_pattern(loop_order, n=8):\n",
    "    \"\"\"\n",
    "    Visualize which elements of B are accessed in sequence.\n",
    "    \"\"\"\n",
    "    accesses = []\n",
    "    \n",
    "    if loop_order == 'ijk':  # Naive\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                for k in range(n):\n",
    "                    accesses.append((k, j))  # B[k, j]\n",
    "    elif loop_order == 'ikj':  # Reordered\n",
    "        for i in range(n):\n",
    "            for k in range(n):\n",
    "                for j in range(n):\n",
    "                    accesses.append((k, j))  # B[k, j]\n",
    "    \n",
    "    return accesses[:64]  # First 64 accesses\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (order, title) in zip(axes, [('ijk', 'Naive (i-j-k): Column-major access'),\n",
    "                                       ('ikj', 'Reordered (i-k-j): Row-major access')]):\n",
    "    accesses = visualize_access_pattern(order)\n",
    "    \n",
    "    # Create grid\n",
    "    grid = np.zeros((8, 8))\n",
    "    for idx, (k, j) in enumerate(accesses):\n",
    "        grid[k, j] = idx + 1\n",
    "    \n",
    "    im = ax.imshow(grid, cmap='YlOrRd')\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.set_xlabel('j (column)')\n",
    "    ax.set_ylabel('k (row)')\n",
    "    \n",
    "    # Show access order for first few\n",
    "    for idx, (k, j) in enumerate(accesses[:20]):\n",
    "        ax.annotate(str(idx), (j, k), ha='center', va='center', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNaive (left): Jumps between columns (stride = N)\")\n",
    "print(\"Reordered (right): Sequential within rows (stride = 1)\")\n",
    "print(\"\\nSequential access is 5-10√ó faster due to caching!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-19",
   "source": [
    "## Investigation: Optimal Tile Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-20",
   "outputs": [],
   "source": [
    "if HAS_NUMBA:\n",
    "    def test_tile_sizes():\n",
    "        tile_sizes = [8, 16, 32, 64, 128]\n",
    "        results = []\n",
    "        \n",
    "        for ts in tile_sizes:\n",
    "            # Create tiled version with this tile size\n",
    "            @jit(nopython=True)\n",
    "            def matmul_tiled_ts(A, B, C, tile_size=ts):\n",
    "                M, K = A.shape\n",
    "                K, N = B.shape\n",
    "                C[:] = 0\n",
    "                for i0 in range(0, M, tile_size):\n",
    "                    for j0 in range(0, N, tile_size):\n",
    "                        for k0 in range(0, K, tile_size):\n",
    "                            i_end = min(i0 + tile_size, M)\n",
    "                            j_end = min(j0 + tile_size, N)\n",
    "                            k_end = min(k0 + tile_size, K)\n",
    "                            for i in range(i0, i_end):\n",
    "                                for k in range(k0, k_end):\n",
    "                                    a_val = A[i, k]\n",
    "                                    for j in range(j0, j_end):\n",
    "                                        C[i, j] += a_val * B[k, j]\n",
    "                return C\n",
    "            \n",
    "            # Warmup\n",
    "            _ = matmul_tiled_ts(A[:64, :64], B[:64, :64], np.zeros((64, 64), dtype=np.float32))\n",
    "            \n",
    "            # Benchmark\n",
    "            times = []\n",
    "            for _ in range(3):\n",
    "                C_test = C.copy()\n",
    "                start = time.perf_counter()\n",
    "                matmul_tiled_ts(A, B, C_test)\n",
    "                times.append(time.perf_counter() - start)\n",
    "            \n",
    "            mean_time = np.mean(times)\n",
    "            flops = 2 * N**3\n",
    "            gflops = flops / mean_time / 1e9\n",
    "            \n",
    "            working_set_kb = 3 * ts * ts * 4 / 1024\n",
    "            results.append((ts, gflops, working_set_kb))\n",
    "            print(f\"Tile {ts:3d}√ó{ts:3d} (working set {working_set_kb:5.1f} KB): {gflops:.2f} GFLOPS\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    print(f\"Testing tile sizes for {N}√ó{N} matrix...\\n\")\n",
    "    tile_results = test_tile_sizes()\n",
    "    \n",
    "    # Visualize\n",
    "    ts = [r[0] for r in tile_results]\n",
    "    gf = [r[1] for r in tile_results]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar([str(t) for t in ts], gf)\n",
    "    plt.xlabel('Tile Size')\n",
    "    plt.ylabel('GFLOPS')\n",
    "    plt.title('Performance vs Tile Size')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° Optimal tile size depends on your cache hierarchy!\")\n",
    "    print(\"   L1: ~32KB, L2: ~256KB, L3: ~8-32MB (typical)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è This investigation requires Numba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-21",
   "source": [
    "## Correctness Check\n",
    "\n",
    "Make sure all implementations compute the same result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-22",
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "C_numpy = A @ B\n",
    "\n",
    "# Test each implementation\n",
    "if HAS_NUMBA:\n",
    "    C_tiled = np.zeros_like(C)\n",
    "    matmul_tiled(A, B, C_tiled)\n",
    "    print(f\"Tiled matches NumPy: {np.allclose(C_numpy, C_tiled)}\")\n",
    "    print(f\"  Max difference: {np.max(np.abs(C_numpy - C_tiled)):.2e}\")\n",
    "    \n",
    "    C_reordered = np.zeros_like(C)\n",
    "    matmul_reordered(A, B, C_reordered)\n",
    "    print(f\"Reordered matches NumPy: {np.allclose(C_numpy, C_reordered)}\")\n",
    "    print(f\"  Max difference: {np.max(np.abs(C_numpy - C_reordered)):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-23",
   "source": [
    "## Your Turn: Experiments\n",
    "\n",
    "1. **Matrix size**: How does performance scale with N?\n",
    "2. **Tile size**: Find the optimal tile size for YOUR hardware.\n",
    "3. **Data types**: Compare float32 vs float64 performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-24",
   "outputs": [],
   "source": [
    "# Your experiments here!\n",
    "\n",
    "# Example: How does NumPy scale with matrix size?\n",
    "def scaling_experiment():\n",
    "    sizes = [64, 128, 256, 512, 1024]\n",
    "    results = []\n",
    "    \n",
    "    for n in sizes:\n",
    "        A = np.random.randn(n, n).astype(np.float32)\n",
    "        B = np.random.randn(n, n).astype(np.float32)\n",
    "        \n",
    "        # Warmup\n",
    "        _ = A @ B\n",
    "        \n",
    "        # Benchmark\n",
    "        times = []\n",
    "        for _ in range(3):\n",
    "            start = time.perf_counter()\n",
    "            _ = A @ B\n",
    "            times.append(time.perf_counter() - start)\n",
    "        \n",
    "        mean_time = np.mean(times)\n",
    "        flops = 2 * n**3\n",
    "        gflops = flops / mean_time / 1e9\n",
    "        \n",
    "        results.append((n, gflops))\n",
    "        print(f\"N={n:5d}: {gflops:6.2f} GFLOPS\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"NumPy scaling with matrix size:\\n\")\n",
    "scaling = scaling_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-25",
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Loop order matters**: i-k-j is ~4√ó faster than i-j-k due to memory access patterns.\n",
    "\n",
    "2. **Tiling transforms memory-bound to compute-bound**: By keeping working set in cache.\n",
    "\n",
    "3. **BLAS is highly optimized**: Uses multi-level tiling, SIMD, and parallelism.\n",
    "\n",
    "4. **The same algorithm can be 200√ó slower**: Without attention to memory hierarchy.\n",
    "\n",
    "5. **Hardware determines optimal tile size**: Match to your cache hierarchy.\n",
    "\n",
    "---\n",
    "\n",
    "*Continue to [Chapter 11: FlashAttention](https://ttsugriy.github.io/performance-book/chapters/11-flash-attention.html)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
